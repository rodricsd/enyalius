# Lista para armazenar os modelos treinados
model_results <- list()
# Loop para treinar cada algoritmo
for (alg in list_alg) {
print(paste("Treinando o modelo com algoritmo:", alg))
# Treinar o modelo com o algoritmo atual
model <- caret::train(x = final_train_set,
y = dependent_variable,
method = alg,
trControl = train_control,
metric = "Accuracy")
# Armazenar o modelo treinado na lista
model_results[[alg]] <- model
}
# Avaliar o desempenho no conjunto de teste #### MUDAR
evaluation_results <- list()
print(list_alg)
for (alg in list_alg) {
print(paste("Avaliando o modelo com algoritmo:", alg))
predictions <- predict(model_results[[alg]], newdata = test_set)
confusion_matrix <- confusionMatrix(predictions, dependent_test_set)
evaluation_results[[alg]] <- confusion_matrix
if (verbose)
print(confusion_matrix)
}
accuracy <- c()
accuracy_sd <- c()
kappa <- c()
kappa_sd <- c()
for (x in list_alg) {
accuracy[x] <- max(model_results[[x]]$results["Accuracy"])
accuracy_sd[x] <- max(model_results[[x]]$results["AccuracySD"])
kappa[x] <- model_results[[x]]$results[1, "Kappa"]
kappa_sd[x] <- model_results[[x]]$results[1, "KappaSD"]
}
res_scores <- data.frame(accuracy = accuracy,
accuracy_sd = accuracy_sd,
kappa = kappa,
kappa_sd = kappa_sd)
accuracy <- c()
accuracy_sd <- c()
kappa <- c()
kappa_sd <- c()
for (x in list_alg) {
max_accuracy <- max(model_results[[x]]$results["Accuracy"])
data <- subset(model_results[[x]]$results, Accuracy == max_accuracy)
data <- subset(data, select = c("Accuracy", "Kappa", "AccuracySD", "KappaSD"))
accuracy[x] <- c(data$Accuracy)
accuracy_sd[x] <- c(data$AccuracySD)
kappa[x] <- c(data$Kappa)
kappa_sd[x] <- c(data$KappaSD)
}
res_scores_df <- data.frame(accuracy = accuracy,
accuracy_sd = accuracy_sd,
kappa = kappa,
kappa_sd = kappa_sd)
print(res_scores_df)
print("Ok!")
# res_scores_order <- res_scores[order(res_scores$accuracy, decreasing = T),]
# Retornar os resultados dos modelos e as avaliações
return(list(m_names = list_alg,
models = model_results,
evaluations = evaluation_results,
order1 = res_scores[order(res_scores$accuracy, decreasing = T),],
order2 = res_scores_df[order(res_scores_df$accuracy, decreasing = T),]))
}
# Testando a função com o dataset 'iris'
library(datasets)
iris <- datasets::iris
seed <- 42
results <- comp_alg(data = iris,
train_val = 0.8,
seed = seed,
cv_folds = 5,
verbose = FALSE)
results$order1
results$order2
library(plotly)
library(tidymodels)
library(pROC)
library(devtools)
library(multiROC)
library(mice)
library(tidyverse)
library(readxl)
library(caret)
library(e1071)
library(glmnet)
library(MLmetrics)
library(caretEnsemble)
library(kernlab)
library(xgboost)
library(fastDummies)
library(randomForest)
library(rpart)
library(RSNNS)
library(klaR)
### Função
comp_alg <- function(data,
list_alg = c("rpart", "nnet", "svmLinear", "rf", "LogitBoost", "knn") ,
train_val = 0.75,
cv_folds,
seed = 123,
number = 5,
repeats = 10,
verbose = TRUE)
{
# Definir seed para reprodutibilidade
set.seed(seed)
# Dividir os dados em treino e teste
in_training <- createDataPartition(y = data[, ncol(data)],
p = train_val,
list = F)
train_set <- data[in_training,]
test_set <- data[-in_training,]
final_train_set <- train_set[,-ncol(train_set)] # Assume que a variável resposta está na última coluna
dependent_variable <- train_set[,ncol(train_set)]
dependent_test_set <- test_set[,ncol(test_set)]
# Definir controle do treino (Validação Cruzada com n folds)
train_control <- trainControl(method = "repeatedcv", number = number, repeats = repeats)
# Lista para armazenar os modelos treinados
model_results <- list()
evaluation_results <- list()
accuracy <- c()
accuracy_sd <- c()
kappa <- c()
kappa_sd <- c()
# Loop para treinar cada algoritmo
for (alg in list_alg) {
cat("Training algorithm:", alg, "\n")
# Treinar o modelo com o algoritmo atual
model <- caret::train(x = final_train_set,
y = dependent_variable,
method = alg,
trControl = train_control,
metric = "Accuracy")
# Armazenar o modelo treinado na lista
model_results[[alg]] <- model
# Previsoes no teste
predictions <- predict(model_results[[alg]], newdata = test_set)
confusion_matrix <- confusionMatrix(predictions, dependent_test_set)
evaluation_results[[alg]] <- confusion_matrix
if (verbose) print(confusion_matrix)
# Obter o modelo treinado com maior acuracia
best_index <- which.max(model$results$Accuracy)
accuracy[alg] <- model$results$Accuracy[best_index]
accuracy_sd[alg] <- model$results$AccuracySD[best_index]
kappa[alg] <- model$results$Kappa[best_index]
kappa_sd[alg] <- model$results$KappaSD[best_index]
}
res_scores <- data.frame(accuracy = accuracy,
accuracy_sd = accuracy_sd,
kappa = kappa,
kappa_sd = kappa_sd)
res_scores <- res_scores[order(res_scores$accuracy, decreasing = TRUE), ]
best_model <- res_scores$algorithm[1]
# Retornar os resultados dos modelos e as avaliações
return(list(
model_names = list_alg,
models = model_results,
evaluations = evaluation_results,
metrics = res_scores,
best_model = best_model))
}
# Testando a função com o dataset 'iris'
library(datasets)
iris <- datasets::iris
seed <- 42
results <- comp_alg(data = iris,
train_val = 0.8,
seed = seed,
cv_folds = 5,
verbose = FALSE)
results$best_model
class(results$metrics)
results$metrics
### Função
comp_alg <- function(data,
target,
list_alg = c("rpart", "nnet", "svmLinear", "rf", "LogitBoost", "knn") ,
train_val = 0.75,
cv_folds = 5,
seed = 123,
number = 5,
repeats = 10,
verbose = TRUE)
{
# Definir seed para reprodutibilidade
set.seed(seed)
# Dividir os dados em treino e teste
in_training <- createDataPartition(y = data[[target]],
p = train_val,
list = FALSE)
train_set <- data[in_training,]
test_set <- data[-in_training,]
#final_train_set <- train_set[,-ncol(train_set)] # Assume que a variável resposta está na última coluna
#dependent_variable <- train_set[,ncol(train_set)]
#dependent_test_set <- test_set[,ncol(test_set)]
final_train_set <- dplyr::select(train_set, -all_of(target))  # preditores
dependent_variable <- train_set[[target]]                     # resposta de treino
dependent_test_set <- test_set[[target]]                     # resposta de teste
# Definir controle do treino (Validação Cruzada com n folds)
train_control <- trainControl(method = "repeatedcv", number = number, repeats = repeats)
# Lista para armazenar os modelos treinados
model_results <- list()
evaluation_results <- list()
accuracy <- c()
accuracy_sd <- c()
kappa <- c()
kappa_sd <- c()
# Loop para treinar cada algoritmo
for (alg in list_alg) {
cat("Training algorithm:", alg, "\n")
# Treinar o modelo com o algoritmo atual
model <- caret::train(x = final_train_set,
y = dependent_variable,
method = alg,
trControl = train_control,
metric = "Accuracy")
# Armazenar o modelo treinado na lista
model_results[[alg]] <- model
# Previsoes no teste
predictions <- predict(model, dplyr::select(test_set, -all_of(target)))
confusion_matrix <- confusionMatrix(predictions, dependent_test_set)
evaluation_results[[alg]] <- confusion_matrix
if (verbose) print(confusion_matrix)
# Obter o modelo treinado com maior acuracia
best_index <- which.max(model$results$Accuracy)
accuracy[alg] <- model$results$Accuracy[best_index]
accuracy_sd[alg] <- model$results$AccuracySD[best_index]
kappa[alg] <- model$results$Kappa[best_index]
kappa_sd[alg] <- model$results$KappaSD[best_index]
}
res_scores <- data.frame(accuracy = accuracy,
accuracy_sd = accuracy_sd,
kappa = kappa,
kappa_sd = kappa_sd)
res_scores <- res_scores[order(res_scores$accuracy, decreasing = TRUE), ]
best_model <- res_scores$algorithm[1]
# Retornar os resultados dos modelos e as avaliações
return(list(
model_names = list_alg,
models = model_results,
evaluations = evaluation_results,
metrics = res_scores,
best_model = best_model
))
}
# Testando a função com o dataset 'iris'
library(datasets)
iris <- datasets::iris
results <- comp_alg(data = iris,
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
results$best_model
### Função
comp_alg <- function(data,
target,
list_alg = c("rpart", "nnet", "svmLinear", "rf", "LogitBoost", "knn") ,
train_val = 0.75,
cv_folds = 5,
seed = 123,
number = 5,
repeats = 10,
verbose = TRUE)
{
# Definir seed para reprodutibilidade
set.seed(seed)
# Dividir os dados em treino e teste
in_training <- createDataPartition(y = data[[target]],
p = train_val,
list = FALSE)
train_set <- data[in_training,]
test_set <- data[-in_training,]
#final_train_set <- train_set[,-ncol(train_set)] # Assume que a variável resposta está na última coluna
#dependent_variable <- train_set[,ncol(train_set)]
#dependent_test_set <- test_set[,ncol(test_set)]
final_train_set <- dplyr::select(train_set, -all_of(target))  # preditores
dependent_variable <- train_set[[target]]                     # resposta de treino
dependent_test_set <- test_set[[target]]                     # resposta de teste
# Definir controle do treino (Validação Cruzada com n folds)
train_control <- trainControl(method = "repeatedcv", number = number, repeats = repeats)
# Lista para armazenar os modelos treinados
model_results <- list()
evaluation_results <- list()
accuracy <- c()
accuracy_sd <- c()
kappa <- c()
kappa_sd <- c()
# Loop para treinar cada algoritmo
for (alg in list_alg) {
cat("Training algorithm:", alg, "\n")
# Treinar o modelo com o algoritmo atual
model <- caret::train(x = final_train_set,
y = dependent_variable,
method = alg,
trControl = train_control,
metric = "Accuracy")
# Armazenar o modelo treinado na lista
model_results[[alg]] <- model
# Previsoes no teste
predictions <- predict(model, dplyr::select(test_set, -all_of(target)))
confusion_matrix <- confusionMatrix(predictions, dependent_test_set)
evaluation_results[[alg]] <- confusion_matrix
if (verbose) print(confusion_matrix)
# Obter o modelo treinado com maior acuracia
best_index <- which.max(model$results$Accuracy)
accuracy[alg] <- model$results$Accuracy[best_index]
accuracy_sd[alg] <- model$results$AccuracySD[best_index]
kappa[alg] <- model$results$Kappa[best_index]
kappa_sd[alg] <- model$results$KappaSD[best_index]
}
res_scores <- data.frame(accuracy = accuracy,
accuracy_sd = accuracy_sd,
kappa = kappa,
kappa_sd = kappa_sd)
res_scores <- res_scores[order(res_scores$accuracy, decreasing = TRUE), ]
best_model <- res_scores$algorithm[1]
# Retornar os resultados dos modelos e as avaliações
return(list(
model_names = list_alg,
models = model_results,
evaluations = evaluation_results,
metrics = res_scores,
best_model = best_model
))
}
# Testando a função com o dataset 'iris'
library(datasets)
iris <- datasets::iris
results <- comp_alg(data = iris,
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
results <- comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
results$best_model
### Função
comp_alg <- function(data,
target,
list_alg = c("rpart", "nnet", "svmLinear", "rf", "LogitBoost", "knn") ,
train_val = 0.75,
cv_folds = 5,
seed = 123,
number = 5,
repeats = 10,
verbose = TRUE)
{
# Definir seed para reprodutibilidade
set.seed(seed)
# Dividir os dados em treino e teste
in_training <- createDataPartition(y = data[[target]],
p = train_val,
list = FALSE)
train_set <- data[in_training,]
test_set <- data[-in_training,]
#final_train_set <- train_set[,-ncol(train_set)] # Assume que a variável resposta está na última coluna
#dependent_variable <- train_set[,ncol(train_set)]
#dependent_test_set <- test_set[,ncol(test_set)]
final_train_set <- dplyr::select(train_set, -all_of(target))  # preditores
dependent_variable <- train_set[[target]]                     # resposta de treino
dependent_test_set <- test_set[[target]]                     # resposta de teste
# Definir controle do treino (Validação Cruzada com n folds)
train_control <- trainControl(method = "repeatedcv", number = number, repeats = repeats)
# Lista para armazenar os modelos treinados
model_results <- list()
evaluation_results <- list()
accuracy <- c()
accuracy_sd <- c()
kappa <- c()
kappa_sd <- c()
# Loop para treinar cada algoritmo
for (alg in list_alg) {
cat("Training algorithm:", alg, "\n")
# Treinar o modelo com o algoritmo atual
model <- caret::train(x = final_train_set,
y = dependent_variable,
method = alg,
trControl = train_control,
metric = "Accuracy")
# Armazenar o modelo treinado na lista
model_results[[alg]] <- model
# Previsoes no teste
predictions <- predict(model, dplyr::select(test_set, -all_of(target)))
confusion_matrix <- confusionMatrix(predictions, dependent_test_set)
evaluation_results[[alg]] <- confusion_matrix
if (verbose) print(confusion_matrix)
# Obter o modelo treinado com maior acuracia
best_index <- which.max(model$results$Accuracy)
accuracy[alg] <- model$results$Accuracy[best_index]
accuracy_sd[alg] <- model$results$AccuracySD[best_index]
kappa[alg] <- model$results$Kappa[best_index]
kappa_sd[alg] <- model$results$KappaSD[best_index]
}
res_scores <- data.frame(accuracy = accuracy,
accuracy_sd = accuracy_sd,
kappa = kappa,
kappa_sd = kappa_sd)
res_scores_ordered <- res_scores[order(res_scores$accuracy, decreasing = TRUE), ]
best_model <- res_scores_ordered$algorithm[1]
# Retornar os resultados dos modelos e as avaliações
return(list(
model_names = list_alg,
models = model_results,
evaluations = evaluation_results,
metrics = res_scores_ordered,
best_model = best_model
))
}
# Testando a função com o dataset 'iris'
library(datasets)
iris <- datasets::iris
results <- comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
results$best_model
class(results$metrics)
results$metrics
# Testando a função com o dataset 'iris'
library(datasets)
library(diagnoseR)
iris <- datasets::iris
results <- comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
results$best_model_0
# Testando a função com o dataset 'iris'
library(datasets)
library(diagnoseR)
iris <- datasets::iris
results <- comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
# Testando a função com o dataset 'iris'
library(datasets)
library(diagnoseR)
iris <- datasets::iris
results <- comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
#
#
# Testando a função com o dataset 'iris'
library(datasets)
library(diagnoseR)
iris <- datasets::iris
results <- comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
results$best_model
# Testando a função com o dataset 'iris'
library(datasets)
library(diagnoseR)
iris <- datasets::iris
results <- diagnoseR::comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
library(devtools)
document("diagnoseR.R")
document("diagnoseR")
install("diagnoseR")
document("diagnoseR")
install("diagnoseR")
q()
library(devtools)
document("diagnoseR")
install("diagnoseR")
q()
# Testando a função com o dataset 'iris'
library(datasets)
library(diagnoseR)
iris <- datasets::iris
results <- diagnoseR::comp_alg(data = iris,
target = "Species",
train_val = 0.8,
seed = 42,
cv_folds = 5,
verbose = FALSE)
results
library(devtools)
document("diagnoseR")
install("diagnoseR")
q()
library(devtools)
document("diagnoseR")
install("diagnoseR")
q()
